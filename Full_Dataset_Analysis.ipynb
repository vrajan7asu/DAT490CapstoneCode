{
 "cells": {
  {
   "cell_type": "markdown",
   "id": "12de2dd2-fe3f-4632-b59d-d05fd65f2984",
   "metadata": {},
   "source": [
    "# 0: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1baf742e-a453-4697-8009-4ba782131683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "\n",
    "# Data cleaning pipeline imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1432cbf5-a069-438f-ae7a-9edd4acdbd85",
   "metadata": {},
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a15c28f-00da-4718-8095-033791c8cd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ProjectID (and not the Project Name) is: vrajan7-cis415-fa24a\n",
      "Bucket name is: vrajan7_data_for_gcp_labs\n",
      "Full path to the data file is gs://vrajan7_data_for_gcp_labs/data_for_traffic/sampled_traffic.csv\n"
     ]
    }
   ],
   "source": [
    "project_id = 'vrajan7-cis415-fa24a'\n",
    "\n",
    "# 2. Configure Bucket name as per your Google Cloud Storage setup\n",
    "bucket = 'vrajan7_data_for_gcp_labs'\n",
    "\n",
    "path_to_data_files = \"/data_for_traffic/\"\n",
    "\n",
    "# traffic_file_name = \"full_traffic.csv\"\n",
    "traffic_file_name = \"sampled_traffic.csv\"\n",
    "\n",
    "# Full Data Path\n",
    "full_file_path = \"gs://\" + bucket + path_to_data_files + traffic_file_name\n",
    "\n",
    "# Let's print out all the configurations and ensure that they are correct\n",
    "print(f\"ProjectID (and not the Project Name) is: {project_id}\")\n",
    "print(f\"Bucket name is: {bucket}\")\n",
    "if traffic_file_name == \"small_data_movie_reviews.txt\":\n",
    "  print(f\"This is running SAMPLED DATASET ({movie_reviews_file_name})\")\n",
    "elif traffic_file_name == \"big_data_movie_reviews.txt\":\n",
    "  print(f\"This is running for FULL DATASET ({movie_reviews_file_name})\")\n",
    "\n",
    "\n",
    "print(f\"Full path to the data file is {full_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f92109d4-3215-411c-aaac-547b067d2bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: apt-get\n",
      "zsh:1: command not found: apt-get\n",
      "zsh:1: command not found: wget\n",
      "tar: Error opening archive: Failed to open 'spark-3.0.0-bin-hadoop3.2.tgz'\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Unable to find py4j in /content/spark-3.0.0-bin-hadoop3.2/python, your SPARK_HOME may not be configured correctly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/traffic/env/lib/python3.12/site-packages/findspark.py:159\u001b[0m, in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     py4j \u001b[38;5;241m=\u001b[39m \u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark_python\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpy4j-*.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 37\u001b[0m\n\u001b[1;32m     34\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39msystem(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpip install -q findspark\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfindspark\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[43mfindspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m     40\u001b[0m spark \u001b[38;5;241m=\u001b[39m SparkSession\u001b[38;5;241m.\u001b[39mbuilder\u001b[38;5;241m.\u001b[39mmaster(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal[*]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mgetOrCreate()\n",
      "File \u001b[0;32m~/Desktop/traffic/env/lib/python3.12/site-packages/findspark.py:161\u001b[0m, in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    159\u001b[0m         py4j \u001b[38;5;241m=\u001b[39m glob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(spark_python, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpy4j-*.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find py4j in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, your SPARK_HOME may not be configured correctly\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    163\u001b[0m                 spark_python\n\u001b[1;32m    164\u001b[0m             )\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    166\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath[:\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m sys_path \u001b[38;5;241m=\u001b[39m [spark_python, py4j]\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# already imported, no need to patch sys.path\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: Unable to find py4j in /content/spark-3.0.0-bin-hadoop3.2/python, your SPARK_HOME may not be configured correctly"
     ]
    }
   ],
   "source": [
    "# Typically, any big data platform (like GCP Dataproc) will have PySpark pre-installed\n",
    "# In all other platforms (e.g. your laptop, Google Colab etc.), PySpark will be not pre-installed.\n",
    "# This paragraph is to check if PySpark is available in the system and install if it's not available\n",
    "# You should expect this paragraph to RUN the PySpark installation in Google Colab\n",
    "# You should expect this paragraph NOT TO RUN the PySpark installation in GCP Dataproc\n",
    "\n",
    "try:\n",
    "  from pyspark.sql import SparkSession\n",
    "  pyspark_available = 'Y'\n",
    "except:\n",
    "  pyspark_available = 'N'\n",
    "\n",
    "# If PySpark is not installed, then go through all these steps\n",
    "\n",
    "if pyspark_available == 'N':\n",
    "  # Update Installer\n",
    "  !apt-get update\n",
    "\n",
    "  # Intsall Java\n",
    "  !apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "  # install spark (change the version number if needed)\n",
    "  !wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz\n",
    "\n",
    "  # unzip the spark file to the current folder\n",
    "  !tar xf spark-3.0.0-bin-hadoop3.2.tgz\n",
    "\n",
    "  # set your spark folder to your system path environment.\n",
    "  import os\n",
    "  os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "  os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-bin-hadoop3.2\"\n",
    "\n",
    "  # install findspark using pip\n",
    "  !pip install -q findspark\n",
    "\n",
    "  import findspark\n",
    "  findspark.init()\n",
    "\n",
    "  from pyspark.sql import SparkSession\n",
    "  spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "  # To access Google Cloud Storage\n",
    "  from google.cloud import storage\n",
    "  import google.auth\n",
    "\n",
    "  !pip install gcsfs\n",
    "  import gcsfs\n",
    "\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()\n",
    "\n",
    "  credentials, default_project_id = google.auth.default()\n",
    "  !gcloud config set project {project_id}\n",
    "else:\n",
    "    # Spark / PySpark already pre-installed in the environment\n",
    "    print(\"PySpark already pre-installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c0fcbf4-d305-475e-b249-9bd28b4f4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_traffic = pd.read_csv('sampled_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b27eb03-7b70-4295-9eee-deb32dec4164",
   "metadata": {},
   "outputs": [],
   "source": [
    "traffic = pd.read_csv('full_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd76ea7a-dcea-49fa-a5a2-9abde09ae9d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-2</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:07:59</td>\n",
       "      <td>2016-02-08 06:37:59</td>\n",
       "      <td>39.928059</td>\n",
       "      <td>-82.831184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-3</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:49:27</td>\n",
       "      <td>2016-02-08 07:19:27</td>\n",
       "      <td>39.063148</td>\n",
       "      <td>-84.032608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-4</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 07:23:34</td>\n",
       "      <td>2016-02-08 07:53:34</td>\n",
       "      <td>39.747753</td>\n",
       "      <td>-84.205582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-5</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 07:39:07</td>\n",
       "      <td>2016-02-08 08:09:07</td>\n",
       "      <td>39.627781</td>\n",
       "      <td>-84.188354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Source  Severity           Start_Time             End_Time  \\\n",
       "0  A-1  Source2         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
       "1  A-2  Source2         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
       "2  A-3  Source2         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n",
       "3  A-4  Source2         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n",
       "4  A-5  Source2         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n",
       "\n",
       "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
       "0  39.865147 -84.058723      NaN      NaN          0.01  ...      False   \n",
       "1  39.928059 -82.831184      NaN      NaN          0.01  ...      False   \n",
       "2  39.063148 -84.032608      NaN      NaN          0.01  ...      False   \n",
       "3  39.747753 -84.205582      NaN      NaN          0.01  ...      False   \n",
       "4  39.627781 -84.188354      NaN      NaN          0.01  ...      False   \n",
       "\n",
       "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
       "0   False  False           False          False        False          Night   \n",
       "1   False  False           False          False        False          Night   \n",
       "2   False  False           False           True        False          Night   \n",
       "3   False  False           False          False        False          Night   \n",
       "4   False  False           False           True        False            Day   \n",
       "\n",
       "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
       "0          Night             Night                 Night  \n",
       "1          Night             Night                   Day  \n",
       "2          Night               Day                   Day  \n",
       "3            Day               Day                   Day  \n",
       "4            Day               Day                   Day  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9056b9f-f2f7-4c1e-bed2-aa061e61a83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7728394"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dac0f78-d54f-4268-ae83-4b174646a30d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             0\n",
       "Source                         0\n",
       "Severity                       0\n",
       "Start_Time                     0\n",
       "End_Time                       0\n",
       "Start_Lat                      0\n",
       "Start_Lng                      0\n",
       "End_Lat                  3402762\n",
       "End_Lng                  3402762\n",
       "Distance(mi)                   0\n",
       "Description                    5\n",
       "Street                     10869\n",
       "City                         253\n",
       "County                         0\n",
       "State                          0\n",
       "Zipcode                     1915\n",
       "Country                        0\n",
       "Timezone                    7808\n",
       "Airport_Code               22635\n",
       "Weather_Timestamp         120228\n",
       "Temperature(F)            163853\n",
       "Wind_Chill(F)            1999019\n",
       "Humidity(%)               174144\n",
       "Pressure(in)              140679\n",
       "Visibility(mi)            177098\n",
       "Wind_Direction            175206\n",
       "Wind_Speed(mph)           571233\n",
       "Precipitation(in)        2203586\n",
       "Weather_Condition         173459\n",
       "Amenity                        0\n",
       "Bump                           0\n",
       "Crossing                       0\n",
       "Give_Way                       0\n",
       "Junction                       0\n",
       "No_Exit                        0\n",
       "Railway                        0\n",
       "Roundabout                     0\n",
       "Station                        0\n",
       "Stop                           0\n",
       "Traffic_Calming                0\n",
       "Traffic_Signal                 0\n",
       "Turning_Loop                   0\n",
       "Sunrise_Sunset             23246\n",
       "Civil_Twilight             23246\n",
       "Nautical_Twilight          23246\n",
       "Astronomical_Twilight      23246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ce698-f7b9-40a4-bde3-d0b041d107ac",
   "metadata": {},
   "source": [
    "# 2. Data Cleaning and Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2b7f254-c32c-4a49-b3d2-3abdd934112b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2016-02-08 05:58:00\n",
       "1    2016-02-08 05:51:00\n",
       "2    2016-02-08 06:56:00\n",
       "3    2016-02-08 07:38:00\n",
       "4    2016-02-08 07:53:00\n",
       "Name: Weather_Timestamp, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic['Weather_Timestamp'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ae2cfab-0172-48a8-bee7-cbd31a93b4b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Light Rain\n",
       "1       Light Rain\n",
       "2         Overcast\n",
       "3    Mostly Cloudy\n",
       "4    Mostly Cloudy\n",
       "Name: Weather_Condition, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic['Weather_Condition'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22620936-a30c-4b5f-a916-11a6244e24be",
   "metadata": {},
   "source": [
    "#### Missing Value Handling Plan: \n",
    "- Because `End_Lat` and `End_Lng` each have 3.4M+ missing values (44.02935% of the full dataset), we chose to drop these columns to focus just on the location of the accident.\n",
    "- `Wind_Speed` and `Precipitation` also have a significant number of missing values. These columns cannot be simply or reliably imputed because of their dependence on time, location, and data collection agencies. However, we did not want to drop these columns because of their possible significance to traffic accident severity. We decided to investigate their relationship with accident severity level using statistical methods (box-plots and ANOVA).\n",
    "- `Street`was dropped from the dataset. Given the granularity of the Lat/Lng coordinates, we did not think we needed this column for our analysis. We figured it could be added back somehow at the end of the analysis, perhaps by creating a unique ID code for each row given Lat/Lng to easily do this but we did not explore this step for this analysis. \n",
    "- `City`, `Zipcode`, `Timezone`, `Airport_Code` can be easily imputed using python packages given the Lat/Lng coordinates. However, we do not see the need to keep all of these variables. We chose to retain `City` and `Zipcode` and impute their missing values in case we wanted to examine traffic accident severity with these columns.\n",
    "- `Weather_Timestamp`, `Temperature`, `Humidity`, `Pressure`, `Visibility`, `Wind_Direction` each do not have excessive missingness. Of these variables, `Visibility` has the most missing values (177,098 missing, 2.29150% of total rows), so we decided to drop rows with missing values in these columns\n",
    "- `Sunrise_Sunset`, `Civil_Twilight`, `Nautical_Twilight`, `Astronomical_Twilight` may have some impact on traffic activity. These variables also likely have some impact on the drowsiness of drivers. However, we chose to drop these columns because they are time columns and to our knowledge, not simply ingested by machine learning algorithms. In the future, we could impute these values using the python `astral` package and figure out how to use this data in an analysis but we chose to focus our analysis on other variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7009039d-5b70-4b01-813d-98ab1c78df2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
