{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12de2dd2-fe3f-4632-b59d-d05fd65f2984",
   "metadata": {
    "id": "12de2dd2-fe3f-4632-b59d-d05fd65f2984"
   },
   "source": [
    "# 0: Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1baf742e-a453-4697-8009-4ba782131683",
   "metadata": {
    "id": "1baf742e-a453-4697-8009-4ba782131683"
   },
   "outputs": [],
   "source": [
    "# General imports\n",
    "import pandas as pd\n",
    "\n",
    "# Data cleaning pipeline imports\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1432cbf5-a069-438f-ae7a-9edd4acdbd85",
   "metadata": {
    "id": "1432cbf5-a069-438f-ae7a-9edd4acdbd85"
   },
   "source": [
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c0fcbf4-d305-475e-b249-9bd28b4f4a10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c0fcbf4-d305-475e-b249-9bd28b4f4a10",
    "outputId": "e3f5a337-5ce6-4114-80b8-ffb4474a8b4e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#traffic = pd.read_csv('/content/sample_data/sampled_traffic.csv')\n",
    "#traffic = pd.read_csv('/content/sample_data/full_traffic.csv')\n",
    "\n",
    "#traffic = pd.read_csv('sampled_traffic.csv')\n",
    "traffic = pd.read_csv('full_traffic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd76ea7a-dcea-49fa-a5a2-9abde09ae9d1",
   "metadata": {
    "id": "bd76ea7a-dcea-49fa-a5a2-9abde09ae9d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>Distance(mi)</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-2</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:07:59</td>\n",
       "      <td>2016-02-08 06:37:59</td>\n",
       "      <td>39.928059</td>\n",
       "      <td>-82.831184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-3</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 06:49:27</td>\n",
       "      <td>2016-02-08 07:19:27</td>\n",
       "      <td>39.063148</td>\n",
       "      <td>-84.032608</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-4</td>\n",
       "      <td>Source2</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 07:23:34</td>\n",
       "      <td>2016-02-08 07:53:34</td>\n",
       "      <td>39.747753</td>\n",
       "      <td>-84.205582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-5</td>\n",
       "      <td>Source2</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-02-08 07:39:07</td>\n",
       "      <td>2016-02-08 08:09:07</td>\n",
       "      <td>39.627781</td>\n",
       "      <td>-84.188354</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "      <td>Day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID   Source  Severity           Start_Time             End_Time  \\\n",
       "0  A-1  Source2         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
       "1  A-2  Source2         2  2016-02-08 06:07:59  2016-02-08 06:37:59   \n",
       "2  A-3  Source2         2  2016-02-08 06:49:27  2016-02-08 07:19:27   \n",
       "3  A-4  Source2         3  2016-02-08 07:23:34  2016-02-08 07:53:34   \n",
       "4  A-5  Source2         2  2016-02-08 07:39:07  2016-02-08 08:09:07   \n",
       "\n",
       "   Start_Lat  Start_Lng  End_Lat  End_Lng  Distance(mi)  ... Roundabout  \\\n",
       "0  39.865147 -84.058723      NaN      NaN          0.01  ...      False   \n",
       "1  39.928059 -82.831184      NaN      NaN          0.01  ...      False   \n",
       "2  39.063148 -84.032608      NaN      NaN          0.01  ...      False   \n",
       "3  39.747753 -84.205582      NaN      NaN          0.01  ...      False   \n",
       "4  39.627781 -84.188354      NaN      NaN          0.01  ...      False   \n",
       "\n",
       "  Station   Stop Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset  \\\n",
       "0   False  False           False          False        False          Night   \n",
       "1   False  False           False          False        False          Night   \n",
       "2   False  False           False           True        False          Night   \n",
       "3   False  False           False          False        False          Night   \n",
       "4   False  False           False           True        False            Day   \n",
       "\n",
       "  Civil_Twilight Nautical_Twilight Astronomical_Twilight  \n",
       "0          Night             Night                 Night  \n",
       "1          Night             Night                   Day  \n",
       "2          Night               Day                   Day  \n",
       "3            Day               Day                   Day  \n",
       "4            Day               Day                   Day  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9056b9f-f2f7-4c1e-bed2-aa061e61a83c",
   "metadata": {
    "id": "e9056b9f-f2f7-4c1e-bed2-aa061e61a83c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7728394"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traffic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dac0f78-d54f-4268-ae83-4b174646a30d",
   "metadata": {
    "id": "5dac0f78-d54f-4268-ae83-4b174646a30d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             0\n",
       "Source                         0\n",
       "Severity                       0\n",
       "Start_Time                     0\n",
       "End_Time                       0\n",
       "Start_Lat                      0\n",
       "Start_Lng                      0\n",
       "End_Lat                  3402762\n",
       "End_Lng                  3402762\n",
       "Distance(mi)                   0\n",
       "Description                    5\n",
       "Street                     10869\n",
       "City                         253\n",
       "County                         0\n",
       "State                          0\n",
       "Zipcode                     1915\n",
       "Country                        0\n",
       "Timezone                    7808\n",
       "Airport_Code               22635\n",
       "Weather_Timestamp         120228\n",
       "Temperature(F)            163853\n",
       "Wind_Chill(F)            1999019\n",
       "Humidity(%)               174144\n",
       "Pressure(in)              140679\n",
       "Visibility(mi)            177098\n",
       "Wind_Direction            175206\n",
       "Wind_Speed(mph)           571233\n",
       "Precipitation(in)        2203586\n",
       "Weather_Condition         173459\n",
       "Amenity                        0\n",
       "Bump                           0\n",
       "Crossing                       0\n",
       "Give_Way                       0\n",
       "Junction                       0\n",
       "No_Exit                        0\n",
       "Railway                        0\n",
       "Roundabout                     0\n",
       "Station                        0\n",
       "Stop                           0\n",
       "Traffic_Calming                0\n",
       "Traffic_Signal                 0\n",
       "Turning_Loop                   0\n",
       "Sunrise_Sunset             23246\n",
       "Civil_Twilight             23246\n",
       "Nautical_Twilight          23246\n",
       "Astronomical_Twilight      23246\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730ce698-f7b9-40a4-bde3-d0b041d107ac",
   "metadata": {
    "id": "730ce698-f7b9-40a4-bde3-d0b041d107ac"
   },
   "source": [
    "# 2. Data Cleaning and Munging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2b7f254-c32c-4a49-b3d2-3abdd934112b",
   "metadata": {
    "id": "e2b7f254-c32c-4a49-b3d2-3abdd934112b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2016-02-08 05:58:00\n",
       "1    2016-02-08 05:51:00\n",
       "2    2016-02-08 06:56:00\n",
       "3    2016-02-08 07:38:00\n",
       "4    2016-02-08 07:53:00\n",
       "Name: Weather_Timestamp, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic['Weather_Timestamp'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ae2cfab-0172-48a8-bee7-cbd31a93b4b3",
   "metadata": {
    "id": "5ae2cfab-0172-48a8-bee7-cbd31a93b4b3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Light Rain\n",
       "1       Light Rain\n",
       "2         Overcast\n",
       "3    Mostly Cloudy\n",
       "4    Mostly Cloudy\n",
       "Name: Weather_Condition, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic['Weather_Condition'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22620936-a30c-4b5f-a916-11a6244e24be",
   "metadata": {
    "id": "22620936-a30c-4b5f-a916-11a6244e24be"
   },
   "source": [
    "#### Missing Value Handling Plan:\n",
    "- Because `End_Lat` and `End_Lng` each have 3.4M+ missing values (44.02935% of the full dataset), we chose to drop these columns to focus just on the location of the accident.\n",
    "- `Wind_Speed` and `Precipitation` also have a significant number of missing values. These columns cannot be simply or reliably imputed because of their dependence on time, location, and data collection agencies. However, we did not want to drop these columns because of their possible significance to traffic accident severity. We decided to investigate their relationship with accident severity level using statistical methods (box-plots and ANOVA).\n",
    "- `Street`was dropped from the dataset. Given the granularity of the Lat/Lng coordinates, we did not think we needed this column for our analysis. We figured it could be added back somehow at the end of the analysis, perhaps by creating a unique ID code for each row given Lat/Lng to easily do this but we did not explore this step for this analysis.\n",
    "- `City`, `Zipcode`, `Timezone`, `Airport_Code` can be easily imputed using python packages given the Lat/Lng coordinates. However, we do not see the need to keep all of these variables. We chose to retain `City` and `Zipcode` and impute their missing values in case we wanted to examine traffic accident severity with these columns.\n",
    "- `Weather_Timestamp`, `Temperature`, `Humidity`, `Pressure`, `Visibility`, `Wind_Direction` each do not have excessive missingness. Of these variables, `Visibility` has the most missing values (177,098 missing, 2.29150% of total rows), so we decided to drop rows with missing values in these columns.\n",
    "- `Sunrise_Sunset`, `Civil_Twilight`, `Nautical_Twilight`, `Astronomical_Twilight` may have some impact on traffic activity. These variables also likely have some impact on the drowsiness of drivers. However, we chose to drop these columns because they are time columns and to our knowledge, not simply ingested by machine learning algorithms. In the future, we could impute these values using the python `astral` package and figure out how to use this data in an analysis but we chose to focus our analysis on other variables.\n",
    "- `Weather_Condition` is an important variable with 173,459 missing values (2.2444% of the full dataset). We considered imputing these values with a nearest-neighbors approach after grouping by city, but were unsure of how this approach would affect the truth in our dataset. We chose to impute mode by city into 'Weather_Condition' instead, understanding that we may be amplifying the effect of certain weather conditions.\n",
    "- `Wind_Speed` has 36,987 missing values. This is not a significant portion of the dataset. We chose to drop na rows from this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "HkaGv5rZoiGR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "HkaGv5rZoiGR",
    "outputId": "c157040a-2fe0-4dd4-b8f6-b5a6b260e2fc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ID', 'Source', 'Severity', 'Start_Time', 'End_Time', 'Start_Lat',\n",
       "       'Start_Lng', 'End_Lat', 'End_Lng', 'Distance(mi)', 'Description',\n",
       "       'Street', 'City', 'County', 'State', 'Zipcode', 'Country', 'Timezone',\n",
       "       'Airport_Code', 'Weather_Timestamp', 'Temperature(F)', 'Wind_Chill(F)',\n",
       "       'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction',\n",
       "       'Wind_Speed(mph)', 'Precipitation(in)', 'Weather_Condition', 'Amenity',\n",
       "       'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway',\n",
       "       'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal',\n",
       "       'Turning_Loop', 'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight',\n",
       "       'Astronomical_Twilight'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traffic.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7009039d-5b70-4b01-813d-98ab1c78df2f",
   "metadata": {
    "id": "7009039d-5b70-4b01-813d-98ab1c78df2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before processing: (7728394, 46)\n",
      "Shape after processing: (7095556, 35)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import pandas as pd\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def get_city(lat, lon):\n",
    "    if pd.isna(lat) or pd.isna(lon):\n",
    "        return None\n",
    "    try:\n",
    "        lat = float(lat)\n",
    "        lon = float(lon)\n",
    "    except ValueError:\n",
    "        return None\n",
    "    if not (-90 <= lat <= 90) or not (-180 <= lon <= 180):\n",
    "        return None\n",
    "    geolocator = Nominatim(user_agent=\"my_agent\")\n",
    "    try:\n",
    "        location = geolocator.reverse(f\"{lat}, {lon}\")\n",
    "        if location and 'address' in location.raw:\n",
    "            address = location.raw['address']\n",
    "            return address.get('city') or address.get('town') or address.get('village')\n",
    "    except (GeocoderTimedOut, GeocoderServiceError, ValueError):\n",
    "        time.sleep(1)  # Wait for 1 second before retrying\n",
    "    return None\n",
    "\n",
    "def fill_missing_city(df):\n",
    "    mask = df['City'].isna()\n",
    "    missing_cities = df[mask]\n",
    "    for idx, row in missing_cities.iterrows():\n",
    "        city = get_city(row['Start_Lat'], row['Start_Lng'])\n",
    "        if city:\n",
    "            df.at[idx, 'City'] = city\n",
    "    return df\n",
    "\n",
    "columns_to_drop = ['End_Lat', 'End_Lng', 'Street', 'Timezone', 'Airport_Code', \n",
    "                   'Sunrise_Sunset', 'Civil_Twilight', 'Nautical_Twilight', \n",
    "                   'Astronomical_Twilight', 'Wind_Chill(F)', 'Precipitation(in)']\n",
    "\n",
    "def preprocess_data(X):\n",
    "    X = X.drop(columns=columns_to_drop)\n",
    "    X = fill_missing_city(X)\n",
    "    X = X.dropna(subset=['City', 'Description'])\n",
    "    X['Weather_Condition'] = X.groupby('City')['Weather_Condition'].transform(\n",
    "        lambda x: x.fillna(x.mode().iloc[0] if not x.mode().empty else 'Unknown')\n",
    "    )\n",
    "    columns_to_check_na = ['Weather_Timestamp', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Direction', 'Wind_Speed(mph)']\n",
    "    X = X.dropna(subset=columns_to_check_na)\n",
    "    return X\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('preprocess', FunctionTransformer(preprocess_data, validate=False))\n",
    "])\n",
    "\n",
    "result = pipeline.fit_transform(traffic)\n",
    "result_df = pd.DataFrame(result, columns=[col for col in traffic.columns if col not in columns_to_drop])\n",
    "print(\"Shape before processing:\", traffic.shape)\n",
    "print(\"Shape after processing:\", result_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905c5529-4427-43d3-a7ba-02ea0848926c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rK41_P4So1FW",
   "metadata": {
    "id": "rK41_P4So1FW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                   0\n",
       "Source               0\n",
       "Severity             0\n",
       "Start_Time           0\n",
       "End_Time             0\n",
       "Start_Lat            0\n",
       "Start_Lng            0\n",
       "Distance(mi)         0\n",
       "Description          0\n",
       "City                 0\n",
       "County               0\n",
       "State                0\n",
       "Zipcode              0\n",
       "Country              0\n",
       "Weather_Timestamp    0\n",
       "Temperature(F)       0\n",
       "Humidity(%)          0\n",
       "Pressure(in)         0\n",
       "Visibility(mi)       0\n",
       "Wind_Direction       0\n",
       "Wind_Speed(mph)      0\n",
       "Weather_Condition    0\n",
       "Amenity              0\n",
       "Bump                 0\n",
       "Crossing             0\n",
       "Give_Way             0\n",
       "Junction             0\n",
       "No_Exit              0\n",
       "Railway              0\n",
       "Roundabout           0\n",
       "Station              0\n",
       "Stop                 0\n",
       "Traffic_Calming      0\n",
       "Traffic_Signal       0\n",
       "Turning_Loop         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7388e43c-3ccb-4890-956f-3fd8693f105b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['Start_Lat', 'Start_Lng', 'Distance(mi)', 'Temperature(F)', 'Humidity(%)', 'Pressure(in)', 'Visibility(mi)', 'Wind_Speed(mph)']\n",
      "Categorical columns: ['ID', 'Source', 'Start_Time', 'End_Time', 'Description', 'City', 'County', 'State', 'Zipcode', 'Country', 'Weather_Timestamp', 'Wind_Direction', 'Weather_Condition', 'Amenity', 'Bump', 'Crossing', 'Give_Way', 'Junction', 'No_Exit', 'Railway', 'Roundabout', 'Station', 'Stop', 'Traffic_Calming', 'Traffic_Signal', 'Turning_Loop']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'severity'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/traffic/env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'severity'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m test_df[categorical_columns]\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_data_categorical.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Save target variable separately\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m \u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseverity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_target.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     41\u001b[0m test_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseverity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_target.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain set shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, train_df\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/Desktop/traffic/env/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/traffic/env/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'severity'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your dataframe is named results_df and the target variable is 'severity'\n",
    "\n",
    "# Separate features and target\n",
    "X = result_df.drop('Severity', axis=1)\n",
    "y = result_df['Severity']\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "numerical_columns = X.select_dtypes(include=[np.number]).columns\n",
    "categorical_columns = X.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "print(\"Numerical columns:\", numerical_columns.tolist())\n",
    "print(\"Categorical columns:\", categorical_columns.tolist())\n",
    "\n",
    "# Perform stratified train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Combine features and target for each split\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Shuffle the rows of each dataframe\n",
    "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "test_df = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Save the full datasets\n",
    "train_df.to_csv('train_data_full.csv', index=False)\n",
    "test_df.to_csv('test_data_full.csv', index=False)\n",
    "\n",
    "# Save numerical and categorical datasets separately\n",
    "train_df[numerical_columns].to_csv('train_data_numerical.csv', index=False)\n",
    "test_df[numerical_columns].to_csv('test_data_numerical.csv', index=False)\n",
    "train_df[categorical_columns].to_csv('train_data_categorical.csv', index=False)\n",
    "test_df[categorical_columns].to_csv('test_data_categorical.csv', index=False)\n",
    "\n",
    "# Save target variable separately\n",
    "train_df['severity'].to_csv('train_target.csv', index=False)\n",
    "test_df['severity'].to_csv('test_target.csv', index=False)\n",
    "\n",
    "print(\"Train set shape:\", train_df.shape)\n",
    "print(\"Test set shape:\", test_df.shape)\n",
    "print(\"Datasets have been saved as CSV files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a15c28f-00da-4718-8095-033791c8cd59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a15c28f-00da-4718-8095-033791c8cd59",
    "outputId": "1c45d068-58a2-42ee-ac74-59df164f9293"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92109d4-3215-411c-aaac-547b067d2bc8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f92109d4-3215-411c-aaac-547b067d2bc8",
    "outputId": "c68365c6-9ba5-4770-ee7d-c183ff68e119"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b474c763-6693-4f88-a49e-b9f2a0e15465",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
